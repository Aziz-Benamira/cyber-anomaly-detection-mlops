data:
  dataset: UNSW
preprocess:
  max_rows: null
train:
  batch_size: 256
  clf_hidden: 256
  d_model: 128
  dropout: 0.1
  epochs_finetune: 10
  epochs_pretrain: 1
  learning_rate: 0.0001
  log_every_n_steps: 50
  mask_ratio: 0.15
  n_classes: 2
  n_heads: 8
  n_layers: 4
  use_cuda: true
