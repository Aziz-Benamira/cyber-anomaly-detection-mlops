# ğŸ” Cyber Anomaly Detection MLOps


![Docker](https://github.com/Aziz-Benamira/cyber-anomaly-detection-mlops/actions/workflows/docker.yml/badge.svg)
![Python](https://img.shields.io/badge/python-3.10-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

![Platform UI Screenshot](./ui.png) 
**End-to-end MLOps project for detecting network intrusions and cyber attacks using a Mixture of Experts (MoE) deep learning architecture.**

This project demonstrates a **complete production-ready machine learning system** with model training, deployment, monitoring, and CI/CD automation for cybersecurity threat detection.

---

## ğŸ“Š Project Overview

### **The Problem**
Detecting cyber attacks in network traffic is critical for security operations centers (SOCs). Traditional rule-based systems struggle with:
- âŒ High false positive rates
- âŒ Inability to detect novel attack patterns
- âŒ Manual analysis bottlenecks
- âŒ Lack of real-time capabilities

### **The Solution**
A **Mixture of Experts (MoE)** deep learning model that:
- âœ… Achieves **98.35% F1-Score** on CICIDS 2017 dataset
- âœ… Combines tabular (FT-Transformer) and temporal (1D-CNN) expert models
- âœ… Detects 6 attack types: DDoS, Port Scan, Web Attack, Brute Force, Infiltration, etc.
- âœ… Real-time predictions via REST API
- âœ… Beautiful dashboard for SOC analysts

### **The MLOps Pipeline**
Complete production infrastructure with:
- ğŸ”¬ **Experiment Tracking** (MLflow)
- ğŸ³ **Containerization** (Docker)
- ğŸ“Š **Monitoring** (Prometheus + Grafana)
- ğŸš€ **CI/CD** (GitHub Actions)
- ğŸ¨ **User Interface** (Streamlit + FastAPI)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA LAYER                                 â”‚
â”‚  ğŸ“Š CICIDS 2017 Dataset (2.8M+ flows)                           â”‚
â”‚  ğŸ”§ Feature Engineering: 72 features (47 tabular + 25 temporal) â”‚
â”‚  ğŸ“¦ DVC: Dataset versioning                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MODEL LAYER (MoE)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Tabular Expert   â”‚        â”‚ Temporal Expert  â”‚              â”‚
â”‚  â”‚ FT-Transformer   â”‚        â”‚    1D-CNN        â”‚              â”‚
â”‚  â”‚  (47 features)   â”‚        â”‚  (25 features)   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚           â”‚                           â”‚                         â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                    â†“                                            â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚           â”‚ Gating Network â”‚                                    â”‚
â”‚           â”‚ (Dynamic Mix)  â”‚                                    â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                    â†“                                            â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚           â”‚  Classifier    â”‚                                    â”‚
â”‚           â”‚ Normal/Attack  â”‚                                    â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“ˆ Performance: F1=98.35% | Precision=97.16% | Recall=99.56%  â”‚
â”‚  âš™ï¸  Parameters: 733,237 (all trained)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MLOPS LAYER                                  â”‚
â”‚  ğŸ”¬ MLflow: Experiment tracking & model registry                â”‚
â”‚  ğŸ³ Docker: Containerized services (API, Prometheus, Grafana)  â”‚
â”‚  ğŸš€ GitHub Actions: CI/CD automation                            â”‚
â”‚  ğŸ“Š Prometheus: Metrics collection                              â”‚
â”‚  ğŸ“ˆ Grafana: Monitoring dashboards                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  APPLICATION LAYER                              â”‚
â”‚  ğŸ”Œ FastAPI: REST API (8000)                                    â”‚
â”‚  ğŸ¨ Streamlit: SOC Dashboard (8501)                             â”‚
â”‚  ğŸ“Š Grafana: Monitoring UI (3000)                               â”‚
â”‚  ğŸ” Prometheus: Metrics UI (9090)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### **Prerequisites**
```bash
# Required
- Python 3.10+
- Docker & Docker Compose
- Git

# Optional (for training)
- NVIDIA GPU with CUDA 11.8+
- 16GB+ RAM
```

### **1. Clone Repository**
```bash
git clone https://github.com/Aziz-Benamira/cyber-anomaly-detection-mlops.git
cd cyber-anomaly-detection-mlops
```

### **2. Install Dependencies**
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install packages
pip install -r requirements.txt
```

### **3. Run with Docker (Recommended)**
```bash
# Start all services (API + Prometheus + Grafana)
docker-compose -f docker/docker-compose.yml up -d

# Check services are running
docker ps

# Access services:
# - API: http://localhost:8000
# - API Docs: http://localhost:8000/docs
# - Prometheus: http://localhost:9090
# - Grafana: http://localhost:3000 (admin/admin)
```

### **4. Run Streamlit Dashboard**
```bash
# Start dashboard
streamlit run src/serving/dashboard.py --server.port 8501

# Access at: http://localhost:8501
```

### **5. Test Predictions**
```bash
# Using Python
python test_quick.py

# Using curl
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d @ddos_attack.json
```

---

## ğŸ“ Project Structure

```
cyber-anomaly-detection-mlops/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/              # GitHub Actions CI/CD
â”‚       â”œâ”€â”€ test.yml           # Automated testing
â”‚       â”œâ”€â”€ docker.yml         # Docker builds
â”‚       â””â”€â”€ deploy.yml         # Deployment
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Original CICIDS 2017 data
â”‚   â”œâ”€â”€ interim/               # Preprocessed data
â”‚   â””â”€â”€ processed/             # Final features + scaler
â”‚       â””â”€â”€ cicids/
â”‚           â”œâ”€â”€ X_train.npy    # Training features
â”‚           â”œâ”€â”€ y_train.npy    # Training labels
â”‚           â””â”€â”€ scaler_stats.json  # Normalization stats
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ load_data.py       # Data loading utilities
â”‚   â”‚   â””â”€â”€ preprocess.py      # Feature engineering
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ moe_model.py       # MoE architecture
â”‚   â”‚   â”œâ”€â”€ train_moe.py       # Training script
â”‚   â”‚   â””â”€â”€ inference.py       # Prediction logic
â”‚   â”‚
â”‚   â””â”€â”€ serving/
â”‚       â”œâ”€â”€ api_prometheus.py  # FastAPI with metrics
â”‚       â”œâ”€â”€ dashboard.py       # Streamlit UI
â”‚       â””â”€â”€ inference.py       # Model wrapper
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ docker-compose.yml     # Service orchestration
â”‚   â”œâ”€â”€ Dockerfile.api         # API container
â”‚   â””â”€â”€ Dockerfile.train       # Training container
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ weights/
â”‚       â””â”€â”€ cicids_moe_best.pt # Trained model (733K params)
â”‚
â”œâ”€â”€ monitoring/
â”‚   â””â”€â”€ prometheus.yml         # Prometheus config
â”‚
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ moe_dashboard.json     # Pre-built dashboard
â”‚   â””â”€â”€ soc_dashboard.json     # SOC analyst view
â”‚
â”œâ”€â”€ tests/                     # Unit tests
â”œâ”€â”€ notebooks/                 # Jupyter notebooks
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ GITHUB_ACTIONS_CICD.md     # CI/CD guide
â”‚   â”œâ”€â”€ PROMETHEUS_GRAFANA_GUIDE.md # Monitoring tutorial
â”‚   â”œâ”€â”€ MLFLOW_UI_TUTORIAL.md      # MLflow usage
â”‚   â””â”€â”€ PHASE*_*.md               # Phase summaries
â”‚
â”œâ”€â”€ params.yaml                # Training hyperparameters
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # This file
```

---

## ğŸ¯ Features

### **Machine Learning**
- âœ… **MoE Architecture**: Combines FT-Transformer (tabular) + 1D-CNN (temporal) experts
- âœ… **State-of-the-Art Performance**: 98.35% F1-Score on CICIDS 2017
- âœ… **Multi-Class Detection**: Normal traffic + 6 attack types
- âœ… **Feature Engineering**: 72 normalized features (flow, forward, backward stats)
- âœ… **Gating Mechanism**: Dynamic weighting of expert contributions

### **MLOps Infrastructure**
- âœ… **Experiment Tracking**: MLflow for metrics, parameters, and model versioning
- âœ… **Dataset Versioning**: DVC for reproducible data pipelines
- âœ… **Containerization**: Docker for consistent environments
- âœ… **Orchestration**: Docker Compose for multi-service deployment
- âœ… **CI/CD**: GitHub Actions for automated testing, building, and deployment
- âœ… **Monitoring**: Prometheus metrics + Grafana dashboards

### **APIs & Interfaces**
- âœ… **REST API**: FastAPI with automatic OpenAPI documentation
- âœ… **SOC Dashboard**: Beautiful Streamlit UI with:
  - Real-time predictions
  - 6 pre-loaded attack examples
  - Custom 72-feature editor
  - Plotly visualizations (gauges, charts, pie charts)
- âœ… **Metrics Endpoint**: Prometheus-compatible `/metrics`
- âœ… **Health Checks**: `/health` endpoint for monitoring

### **Monitoring & Observability**
- âœ… **6 Custom Metrics**:
  - `predictions_total`: Counter by prediction class
  - `prediction_confidence`: Confidence scores
  - `expert_gating_weight`: Expert contribution tracking
  - `prediction_duration_seconds`: Latency monitoring
  - `api_requests_total`: Request tracking
  - `model_loaded`: Model status indicator
- âœ… **Pre-built Dashboards**: Grafana dashboards for SOC teams
- âœ… **Real-time Alerts**: Configurable alerting rules

---

## ğŸ“Š Model Performance

### **CICIDS 2017 Dataset**
- **Total Samples**: 2,830,743 network flows
- **Features**: 72 engineered features
- **Classes**: Binary (Normal vs Attack)
- **Attack Types**: DDoS, Port Scan, Web Attack, Brute Force, Infiltration, DoS

### **Results**
| Metric | Score |
|--------|-------|
| **F1-Score** | 98.35% |
| **Precision** | 97.16% |
| **Recall** | 99.56% |
| **Accuracy** | 98.12% |

### **Model Details**
- **Architecture**: Mixture of Experts (MoE)
- **Experts**: 
  - FT-Transformer (47 tabular features)
  - 1D-CNN (25 temporal features)
- **Parameters**: 733,237 (all trained)
- **Training Time**: ~2-3 hours on GPU
- **Inference Time**: ~5-10ms per sample

### **Expert Contributions**
- **Tabular Expert Weight**: ~98.4% (dominates on structured features)
- **Temporal Expert Weight**: ~1.6% (helps with sequential patterns)

---

## ğŸ”§ Usage

### **Training the Model**

```bash
# Basic training
python -m src.models.train_moe --stage train --params params.yaml

# With custom parameters
python -m src.models.train_moe \
  --stage train \
  --params params.yaml \
  --epochs 50 \
  --batch_size 512
```

**Training parameters** (in `params.yaml`):
```yaml
train:
  batch_size: 512
  epochs: 30
  learning_rate: 0.0003
  weight_decay: 1e-05
  early_stopping_patience: 5
  
model:
  ft_transformer:
    n_blocks: 3
    d_token: 192
    attention_dropout: 0.2
  
  cnn:
    channels: [64, 128, 256]
    kernel_size: 3
```

### **Making Predictions**

#### **Python API**
```python
import requests
import json

# Load example attack pattern
with open('ddos_attack.json', 'r') as f:
    features = json.load(f)

# Make prediction
response = requests.post(
    'http://localhost:8000/predict',
    json={'features': features}
)

result = response.json()
print(f"Prediction: {result['prediction']}")        # "Attack"
print(f"Confidence: {result['confidence']:.2%}")   # 99.99%
print(f"Expert Weights: {result['gating_weights']}")
```

#### **cURL**
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d @port_scan.json
```

#### **Streamlit Dashboard**
```bash
streamlit run src/serving/dashboard.py --server.port 8501

# Then:
# 1. Select attack pattern from dropdown
# 2. Click "Analyze Traffic"
# 3. View results with visualizations
```

### **Custom Feature Editing**

The Streamlit dashboard allows creating custom traffic patterns:

1. Select **"Custom"** from dropdown
2. Edit any of the 72 features in 3 tabs:
   - ğŸ“Š Flow Features (0-23)
   - ğŸ”„ Forward Features (24-47)
   - â¬…ï¸ Backward Features (48-71)
3. Click **"Analyze Traffic"**
4. View prediction and confidence

**Example custom pattern**:
```
Flow Duration: 0.5
Total Fwd Packets: 2.5
Fwd Packet Length Mean: 1.8
SYN Flag Count: 3.0
... (72 features total)
```

---

## ğŸ“ˆ Monitoring

### **Prometheus Metrics**

Access metrics at: `http://localhost:8000/metrics`

**Sample queries** (in Prometheus UI):
```promql
# Total predictions by class
predictions_total

# Prediction rate (per second)
rate(predictions_total[5m])

# Average confidence score
avg(prediction_confidence)

# Expert weight distribution
expert_gating_weight

# API latency (95th percentile)
histogram_quantile(0.95, prediction_duration_seconds_bucket)
```

### **Grafana Dashboards**

1. Access Grafana: `http://localhost:3000` (admin/admin)
2. Add Prometheus data source:
   - URL: `http://prometheus:9090`
   - Click "Save & Test"
3. Import pre-built dashboard:
   - Upload `grafana/moe_dashboard.json`
   - Select Prometheus data source
   - Click "Import"

**Dashboard panels**:
- ğŸ“Š Predictions over time
- ğŸ¯ Attack detection rate
- âš¡ API latency
- ğŸ”€ Expert weight distribution
- ğŸ“ˆ Request rate
- ğŸ’¾ Model status

**Tutorial**: See `docs/PROMETHEUS_GRAFANA_GUIDE.md`

---

## ğŸš€ CI/CD Pipeline

### **GitHub Actions Workflows**

We use 3 automated workflows:

#### **1. Test Workflow** (`.github/workflows/test.yml`)
**Triggers**: Push to main/dev, Pull Requests  
**What it does**:
- âœ… Runs linting (flake8)
- âœ… Runs unit tests (pytest)
- âœ… Generates coverage report
- âœ… Uploads to Codecov (optional)

```yaml
# Runs automatically on:
git push origin main
git push origin feature-branch
# Or when opening a Pull Request
```

#### **2. Docker Workflow** (`.github/workflows/docker.yml`)
**Triggers**: Push to main, Version tags, Manual  
**What it does**:
- âœ… Builds API Docker image
- âœ… Builds Training Docker image
- âœ… Tags with version/branch/SHA
- âœ… Pushes to GitHub Container Registry

```yaml
# Runs automatically on:
git push origin main
git tag v1.0.0 && git push origin v1.0.0
# Or manually from GitHub Actions UI
```

**Images published to**:
- `ghcr.io/aziz-benamira/cyber-anomaly-detection-mlops/moe-api:main`
- `ghcr.io/aziz-benamira/cyber-anomaly-detection-mlops/moe-train:main`

#### **3. Deploy Workflow** (`.github/workflows/deploy.yml`)
**Triggers**: Manual, Version tags  
**What it does**:
- âœ… Deploys to staging/production
- âœ… Runs health checks
- âœ… Sends notifications

```bash
# Manual deployment:
# GitHub â†’ Actions â†’ Deploy to Production â†’ Run workflow
# Select environment (staging/production) â†’ Run

# Automatic on version tags:
git tag v1.0.0 && git push origin v1.0.0
```

### **Development Workflow**

```bash
# 1. Create feature branch
git checkout -b feature/new-detector

# 2. Make changes, commit
git add .
git commit -m "Add new attack detector"

# 3. Push (tests run automatically)
git push origin feature/new-detector

# 4. Open Pull Request
# â†’ Tests must pass before merge
# â†’ Code review required

# 5. Merge to main
# â†’ Docker images built automatically
# â†’ Ready to deploy
```

**Complete guide**: `docs/GITHUB_ACTIONS_CICD.md`

---

## ğŸ“š Documentation

Comprehensive guides in `docs/`:

| Document | Description |
|----------|-------------|
| **GITHUB_ACTIONS_CICD.md** | Complete CI/CD guide with examples |
| **PROMETHEUS_GRAFANA_GUIDE.md** | Monitoring setup and usage tutorial |
| **MONITORING_TUTORIAL.md** | Detailed monitoring configuration |
| **MLFLOW_UI_TUTORIAL.md** | MLflow experiment tracking guide |
| **DOCKER_ESSENTIALS.md** | Docker and containerization reference |
| **PHASE5_CICD.md** | CI/CD implementation summary |
| **COMPLETE_PROJECT_SUMMARY.md** | Full project overview |
| **MLOPS_COMPLETE.md** | MLOps pipeline summary |

---

## ğŸ§ª Testing

### **Run Tests**
```bash
# All tests
pytest tests/ -v

# With coverage
pytest tests/ --cov=src --cov-report=html

# Specific test file
pytest tests/test_model.py -v

# Specific test function
pytest tests/test_api.py::test_predict_endpoint -v
```

### **Test Files**
```
tests/
â”œâ”€â”€ test_model.py          # Model architecture tests
â”œâ”€â”€ test_preprocessing.py  # Feature engineering tests
â”œâ”€â”€ test_api.py           # API endpoint tests
â””â”€â”€ test_inference.py     # Prediction logic tests
```

### **Quick Validation**
```bash
# Test API locally
python test_api_local.py

# Test known attack patterns
python test_known_samples.py

# Test port scan detection
python test_port_scan_detection.py

# Quick end-to-end test
python test_quick.py
```

---

## ğŸ³ Docker Deployment

### **Services**

```yaml
services:
  api:
    image: moe-api
    ports: ["8000:8000"]
    healthcheck: /health
    
  prometheus:
    image: prom/prometheus
    ports: ["9090:9090"]
    
  grafana:
    image: grafana/grafana
    ports: ["3000:3000"]
```

### **Commands**

```bash
# Build images
docker-compose -f docker/docker-compose.yml build

# Start services
docker-compose -f docker/docker-compose.yml up -d

# View logs
docker-compose -f docker/docker-compose.yml logs -f api

# Stop services
docker-compose -f docker/docker-compose.yml down

# Rebuild and restart
docker-compose -f docker/docker-compose.yml up --build -d
```

### **Health Checks**

```bash
# API health
curl http://localhost:8000/health

# Prometheus targets
curl http://localhost:9090/api/v1/targets

# Container status
docker ps
```

---

## ğŸ”¬ Experiments with MLflow

### **Start MLflow UI**
```bash
mlflow ui --port 5000

# Access at: http://localhost:5000
```

### **Track Experiments**
```python
import mlflow

mlflow.set_experiment("moe-training")

with mlflow.start_run():
    mlflow.log_params({
        "learning_rate": 0.0003,
        "batch_size": 512,
        "epochs": 30
    })
    
    # Train model...
    
    mlflow.log_metrics({
        "f1_score": 0.9835,
        "precision": 0.9716,
        "recall": 0.9956
    })
    
    mlflow.pytorch.log_model(model, "model")
```

### **Model Registry**
```python
# Register model
mlflow.register_model(
    model_uri="runs:/abc123/model",
    name="moe-cicids-detector"
)

# Load model
model = mlflow.pytorch.load_model("models:/moe-cicids-detector/production")
```

---

## ğŸ“ What You'll Learn

This project demonstrates:

âœ… **Machine Learning**
- Deep learning architecture design (MoE)
- Feature engineering for cybersecurity
- Model training and optimization
- Performance evaluation

âœ… **MLOps Best Practices**
- Experiment tracking (MLflow)
- Dataset versioning (DVC)
- Model registry and lifecycle management
- Reproducible pipelines

âœ… **DevOps & Infrastructure**
- Docker containerization
- Multi-service orchestration
- CI/CD automation (GitHub Actions)
- Monitoring and observability

âœ… **API Development**
- REST API design (FastAPI)
- API documentation (OpenAPI/Swagger)
- Request validation and error handling
- Performance optimization

âœ… **Monitoring & Alerting**
- Prometheus metrics collection
- Grafana dashboard creation
- Custom metrics and alerts
- Production monitoring best practices

---

## ğŸ“– Example Use Cases

### **1. SOC Analyst Dashboard**
```
Analyst opens Streamlit dashboard
â†’ Selects "DDoS Attack" example
â†’ Clicks "Analyze Traffic"
â†’ Sees: 99.99% Attack confidence
â†’ Views expert weights and feature importance
â†’ Makes informed decision
```

### **2. Real-time API Integration**
```python
# SIEM integration example
def check_traffic(flow_features):
    response = requests.post(
        'http://api:8000/predict',
        json={'features': flow_features}
    )
    result = response.json()
    
    if result['prediction'] == 'Attack' and result['confidence'] > 0.95:
        trigger_alert(flow_features, result)
```

### **3. Batch Processing**
```python
# Process multiple flows
flows = load_pcap_flows('traffic.pcap')

for flow in flows:
    features = extract_features(flow)
    prediction = model.predict(features)
    
    if prediction == 'Attack':
        log_to_siem(flow, prediction)
```

### **4. Custom Attack Research**
```
Researcher uses Custom mode
â†’ Adjusts SYN flag count to 5.0
â†’ Sets packet rate to 10.0
â†’ Modifies flow duration to 0.1
â†’ Clicks "Analyze"
â†’ Studies how model responds to variations
```

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

**Code quality checks**:
- âœ… Tests must pass (`pytest`)
- âœ… Linting must pass (`flake8`)
- âœ… Coverage > 80%

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Dataset**: [CICIDS 2017](https://www.unb.ca/cic/datasets/ids-2017.html) by Canadian Institute for Cybersecurity
- **Architecture**: Inspired by FT-Transformer and Mixture of Experts research
- **Tools**: MLflow, PyTorch, FastAPI, Streamlit, Prometheus, Grafana, Docker

---

## ğŸ“§ Contact

**Aziz Benamira**
- GitHub: [@Aziz-Benamira](https://github.com/Aziz-Benamira)
- Project: [cyber-anomaly-detection-mlops](https://github.com/Aziz-Benamira/cyber-anomaly-detection-mlops)

---

## ğŸ—ºï¸ Roadmap

Future enhancements:

- [ ] Add more attack types (e.g., Botnet, Ransomware)
- [ ] Implement online learning for model updates
- [ ] Add explainability (SHAP, LIME)
- [ ] Multi-model ensemble voting
- [ ] Real-time stream processing (Kafka)
- [ ] Auto-scaling deployment (Kubernetes)
- [ ] Advanced alerting (PagerDuty, Slack)
- [ ] Model drift detection
- [ ] A/B testing framework
- [ ] Multi-tenancy support

---

## ğŸ“Š Project Statistics

- **Lines of Code**: ~15,000+
- **Model Parameters**: 733,237
- **Dataset Size**: 2.8M+ samples
- **Features**: 72 engineered features
- **Accuracy**: 98.35% F1-Score
- **API Latency**: ~5-10ms
- **Docker Images**: 2 (API, Training)
- **CI/CD Workflows**: 3 (Test, Build, Deploy)
- **Documentation**: 10+ guides
- **Tests**: 50+ unit tests

---

<div align="center">

**â­ Star this repo if you find it useful! â­**

Built with â¤ï¸ for the cybersecurity and MLOps communities

</div>
